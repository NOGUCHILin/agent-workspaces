"""
ç«¶åˆè²·å–ä¾¡æ ¼ã®æ¯”è¼ƒåˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã˜ã‚ƒã‚“ã±ã‚‰ã¨ã‚¤ã‚ªã‚·ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚’é›†è¨ˆãƒ»åˆ†æã—ã¦ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚
"""

import json
import pandas as pd
from pathlib import Path
from datetime import datetime
import re


def load_all_data(site: str) -> list[dict]:
    """æŒ‡å®šã‚µã‚¤ãƒˆã®å…¨ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    data_dir = Path(__file__).parent.parent / "data" / "raw" / site
    all_data = []

    if not data_dir.exists():
        print(f"âš ï¸ {site}ã®ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {data_dir}")
        return all_data

    json_files = list(data_dir.glob("*.json"))
    print(f"ğŸ“‚ {site}: {len(json_files)}ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹")

    for json_file in json_files:
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if isinstance(data, list):
                    all_data.extend(data)
                else:
                    all_data.append(data)
        except Exception as e:
            print(f"  âš ï¸ èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {json_file.name} - {e}")

    print(f"  âœ“ {len(all_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿")
    return all_data


def normalize_model_name(model: str) -> str:
    """ãƒ¢ãƒ‡ãƒ«åã‚’æ­£è¦åŒ–"""
    # ç©ºç™½ã‚„æ”¹è¡Œã‚’å‰Šé™¤
    model = re.sub(r'\s+', ' ', model).strip()
    # "iPhone" ã®å¾Œã®ç©ºç™½ã‚’çµ±ä¸€
    model = re.sub(r'iPhone\s+', 'iPhone ', model)
    return model


def analyze_by_model(df: pd.DataFrame) -> pd.DataFrame:
    """ãƒ¢ãƒ‡ãƒ«åˆ¥ã®åˆ†æ"""
    if df.empty:
        return pd.DataFrame()

    # ãƒ¢ãƒ‡ãƒ«åã‚’æ­£è¦åŒ–
    df['model_normalized'] = df['model'].apply(normalize_model_name)

    # ãƒ¢ãƒ‡ãƒ«+å®¹é‡ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    grouped = df.groupby(['model_normalized', 'capacity', 'site'])

    stats = grouped['buyback_price'].agg([
        ('count', 'count'),
        ('mean', 'mean'),
        ('median', 'median'),
        ('min', 'min'),
        ('max', 'max'),
        ('std', 'std'),
    ]).reset_index()

    # åˆ—åã‚’æ—¥æœ¬èªåŒ–
    stats.columns = ['ãƒ¢ãƒ‡ãƒ«', 'å®¹é‡', 'ã‚µã‚¤ãƒˆ', 'ãƒ‡ãƒ¼ã‚¿ä»¶æ•°', 'å¹³å‡ä¾¡æ ¼', 'ä¸­å¤®å€¤', 'æœ€å®‰å€¤', 'æœ€é«˜å€¤', 'æ¨™æº–åå·®']

    # ä¾¡æ ¼ã‚’æ•´æ•°ã«
    for col in ['å¹³å‡ä¾¡æ ¼', 'ä¸­å¤®å€¤', 'æœ€å®‰å€¤', 'æœ€é«˜å€¤', 'æ¨™æº–åå·®']:
        stats[col] = stats[col].fillna(0).astype(int)

    # ã‚½ãƒ¼ãƒˆ
    stats = stats.sort_values(['ãƒ¢ãƒ‡ãƒ«', 'å®¹é‡', 'ã‚µã‚¤ãƒˆ'])

    return stats


def create_comparison_table(df: pd.DataFrame) -> pd.DataFrame:
    """ã‚µã‚¤ãƒˆé–“ã®ä¾¡æ ¼æ¯”è¼ƒè¡¨ã‚’ä½œæˆ"""
    if df.empty:
        return pd.DataFrame()

    # ãƒ¢ãƒ‡ãƒ«åã‚’æ­£è¦åŒ–
    df['model_normalized'] = df['model'].apply(normalize_model_name)

    # ãƒ¢ãƒ‡ãƒ«+å®¹é‡+ã‚µã‚¤ãƒˆã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦ä¸­å¤®å€¤ã‚’å–å¾—
    pivot_data = []

    for (model, capacity), group in df.groupby(['model_normalized', 'capacity']):
        row = {
            'ãƒ¢ãƒ‡ãƒ«': model,
            'å®¹é‡': capacity,
        }

        for site in ['ã˜ã‚ƒã‚“ã±ã‚‰', 'ã‚¤ã‚ªã‚·ã‚¹']:
            site_data = group[group['site'] == site]
            if not site_data.empty:
                row[f'{site}_ä¸­å¤®å€¤'] = int(site_data['buyback_price'].median())
                row[f'{site}_ä»¶æ•°'] = len(site_data)
            else:
                row[f'{site}_ä¸­å¤®å€¤'] = None
                row[f'{site}_ä»¶æ•°'] = 0

        # ä¾¡æ ¼å·®ã‚’è¨ˆç®—
        if row.get('ã˜ã‚ƒã‚“ã±ã‚‰_ä¸­å¤®å€¤') and row.get('ã‚¤ã‚ªã‚·ã‚¹_ä¸­å¤®å€¤'):
            diff = row['ã‚¤ã‚ªã‚·ã‚¹_ä¸­å¤®å€¤'] - row['ã˜ã‚ƒã‚“ã±ã‚‰_ä¸­å¤®å€¤']
            row['ä¾¡æ ¼å·®'] = diff
            row['ä¾¡æ ¼å·®ç‡'] = f"{(diff / row['ã˜ã‚ƒã‚“ã±ã‚‰_ä¸­å¤®å€¤'] * 100):.1f}%"
        else:
            row['ä¾¡æ ¼å·®'] = None
            row['ä¾¡æ ¼å·®ç‡'] = None

        pivot_data.append(row)

    comparison_df = pd.DataFrame(pivot_data)

    # ã‚½ãƒ¼ãƒˆ
    comparison_df = comparison_df.sort_values(['ãƒ¢ãƒ‡ãƒ«', 'å®¹é‡'])

    return comparison_df


def create_normalized_data(df: pd.DataFrame) -> pd.DataFrame:
    """æ­£è¦åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆï¼ˆæ©Ÿç¨®ãƒ»å®¹é‡ãƒ»è²·å–ãƒ©ãƒ³ã‚¯ãƒ»ä¼æ¥­åã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ§‹é€ ï¼‰"""
    if df.empty:
        return pd.DataFrame()

    # ãƒ¢ãƒ‡ãƒ«åã‚’æ­£è¦åŒ–
    df['model_normalized'] = df['model'].apply(normalize_model_name)

    # å¿…è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’é¸æŠãƒ»ãƒªãƒãƒ¼ãƒ 
    normalized_df = df[['model_normalized', 'capacity', 'condition', 'site', 'buyback_price']].copy()
    normalized_df.columns = ['æ©Ÿç¨®', 'å®¹é‡', 'è²·å–ãƒ©ãƒ³ã‚¯', 'ä¼æ¥­å', 'è²·å–ä¾¡æ ¼']

    # é‡è¤‡ã‚’é™¤å¤–ï¼ˆåŒã˜æ©Ÿç¨®ãƒ»å®¹é‡ãƒ»è²·å–ãƒ©ãƒ³ã‚¯ãƒ»ä¼æ¥­åãƒ»è²·å–ä¾¡æ ¼ã®çµ„ã¿åˆã‚ã›ã¯1ä»¶ã®ã¿ï¼‰
    normalized_df = normalized_df.drop_duplicates()

    # ã‚½ãƒ¼ãƒˆï¼ˆæ©Ÿç¨® â†’ å®¹é‡ â†’ ä¼æ¥­å â†’ è²·å–ãƒ©ãƒ³ã‚¯ â†’ è²·å–ä¾¡æ ¼ï¼‰
    normalized_df = normalized_df.sort_values(['æ©Ÿç¨®', 'å®¹é‡', 'ä¼æ¥­å', 'è²·å–ãƒ©ãƒ³ã‚¯', 'è²·å–ä¾¡æ ¼'], ascending=[True, True, True, True, False])

    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ
    normalized_df = normalized_df.reset_index(drop=True)

    return normalized_df


def generate_report(janpara_data: list, iosys_data: list) -> None:
    """ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    print("\n" + "=" * 60)
    print("ç«¶åˆè²·å–ä¾¡æ ¼åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")
    print("=" * 60)

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
    df_janpara = pd.DataFrame(janpara_data) if janpara_data else pd.DataFrame()
    df_iosys = pd.DataFrame(iosys_data) if iosys_data else pd.DataFrame()

    # çµ±åˆ
    df_all = pd.concat([df_janpara, df_iosys], ignore_index=True)

    if df_all.empty:
        print("âŒ åˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    print(f"ğŸ“Š ç·ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(df_all)}ä»¶")
    print(f"  - ã˜ã‚ƒã‚“ã±ã‚‰: {len(df_janpara)}ä»¶")
    print(f"  - ã‚¤ã‚ªã‚·ã‚¹: {len(df_iosys)}ä»¶")

    # æ­£è¦åŒ–ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    print("\nğŸ“‹ æ­£è¦åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆä¸­...")
    normalized_df = create_normalized_data(df_all)

    # ãƒ¢ãƒ‡ãƒ«åˆ¥çµ±è¨ˆ
    print("ğŸ“ˆ ãƒ¢ãƒ‡ãƒ«åˆ¥çµ±è¨ˆã‚’ä½œæˆä¸­...")
    stats_df = analyze_by_model(df_all)

    # ã‚µã‚¤ãƒˆé–“æ¯”è¼ƒè¡¨
    print("ğŸ”„ ã‚µã‚¤ãƒˆé–“æ¯”è¼ƒè¡¨ã‚’ä½œæˆä¸­...")
    comparison_df = create_comparison_table(df_all)

    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    report_dir = Path(__file__).parent.parent / "reports"
    report_dir.mkdir(parents=True, exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # CSVä¿å­˜ï¼ˆæ­£è¦åŒ–ãƒ‡ãƒ¼ã‚¿ï¼‰
    normalized_csv_path = report_dir / f"normalized_data_{timestamp}.csv"
    normalized_df.to_csv(normalized_csv_path, index=False, encoding='utf-8-sig')
    print(f"\nğŸ’¾ æ­£è¦åŒ–ãƒ‡ãƒ¼ã‚¿: {normalized_csv_path}")

    # CSVä¿å­˜ï¼ˆãƒ¢ãƒ‡ãƒ«åˆ¥çµ±è¨ˆï¼‰
    csv_path = report_dir / f"competitor_analysis_{timestamp}.csv"
    stats_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
    print(f"ğŸ’¾ ãƒ¢ãƒ‡ãƒ«åˆ¥çµ±è¨ˆ: {csv_path}")

    # CSVä¿å­˜ï¼ˆã‚µã‚¤ãƒˆé–“æ¯”è¼ƒï¼‰
    comparison_csv_path = report_dir / f"competitor_comparison_{timestamp}.csv"
    comparison_df.to_csv(comparison_csv_path, index=False, encoding='utf-8-sig')
    print(f"ğŸ’¾ ã‚µã‚¤ãƒˆé–“æ¯”è¼ƒ: {comparison_csv_path}")

    # Excelä¿å­˜ï¼ˆè¤‡æ•°ã‚·ãƒ¼ãƒˆï¼‰
    excel_path = report_dir / f"competitor_analysis_{timestamp}.xlsx"
    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
        # ã‚µãƒãƒªãƒ¼ã‚·ãƒ¼ãƒˆ
        summary_data = {
            'é …ç›®': [
                'åˆ†ææ—¥æ™‚',
                'ã˜ã‚ƒã‚“ã±ã‚‰ãƒ‡ãƒ¼ã‚¿ä»¶æ•°',
                'ã‚¤ã‚ªã‚·ã‚¹ãƒ‡ãƒ¼ã‚¿ä»¶æ•°',
                'ç·ãƒ‡ãƒ¼ã‚¿ä»¶æ•°',
                'åˆ†æãƒ¢ãƒ‡ãƒ«æ•°',
            ],
            'å€¤': [
                datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                len(df_janpara),
                len(df_iosys),
                len(df_all),
                len(df_all['model'].unique()) if 'model' in df_all.columns else 0,
            ]
        }
        summary_df = pd.DataFrame(summary_data)
        summary_df.to_excel(writer, sheet_name='1_ã‚µãƒãƒªãƒ¼', index=False)

        # æ­£è¦åŒ–ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ¼ãƒˆï¼ˆæœ€ã‚‚é‡è¦ï¼‰
        normalized_df.to_excel(writer, sheet_name='2_æ­£è¦åŒ–ãƒ‡ãƒ¼ã‚¿', index=False)

        # ã‚µã‚¤ãƒˆé–“æ¯”è¼ƒã‚·ãƒ¼ãƒˆ
        comparison_df.to_excel(writer, sheet_name='3_ã‚µã‚¤ãƒˆé–“æ¯”è¼ƒ', index=False)

        # ãƒ¢ãƒ‡ãƒ«åˆ¥çµ±è¨ˆã‚·ãƒ¼ãƒˆ
        stats_df.to_excel(writer, sheet_name='4_ãƒ¢ãƒ‡ãƒ«åˆ¥çµ±è¨ˆ', index=False)

    print(f"ğŸ’¾ Excelãƒ¬ãƒãƒ¼ãƒˆï¼ˆ4ã‚·ãƒ¼ãƒˆï¼‰: {excel_path}")

    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print("\n" + "=" * 60)
    print("ğŸ“Š åˆ†æã‚µãƒãƒªãƒ¼")
    print("=" * 60)

    if not comparison_df.empty:
        # ä¾¡æ ¼å·®ã®ã‚ã‚‹ä¸»è¦ãƒ¢ãƒ‡ãƒ«ã‚’è¡¨ç¤º
        comparison_with_diff = comparison_df[comparison_df['ä¾¡æ ¼å·®'].notna()].copy()
        if not comparison_with_diff.empty:
            print("\nğŸ” ä¾¡æ ¼å·®ãŒå¤§ãã„ãƒ¢ãƒ‡ãƒ« TOP10:")
            top10 = comparison_with_diff.nlargest(10, 'ä¾¡æ ¼å·®')
            for idx, row in top10.iterrows():
                print(f"  {row['ãƒ¢ãƒ‡ãƒ«']} {row['å®¹é‡']}")
                print(f"    ã˜ã‚ƒã‚“ã±ã‚‰: Â¥{row['ã˜ã‚ƒã‚“ã±ã‚‰_ä¸­å¤®å€¤']:,} ({row['ã˜ã‚ƒã‚“ã±ã‚‰_ä»¶æ•°']}ä»¶)")
                print(f"    ã‚¤ã‚ªã‚·ã‚¹: Â¥{row['ã‚¤ã‚ªã‚·ã‚¹_ä¸­å¤®å€¤']:,} ({row['ã‚¤ã‚ªã‚·ã‚¹_ä»¶æ•°']}ä»¶)")
                print(f"    å·®é¡: Â¥{row['ä¾¡æ ¼å·®']:,} ({row['ä¾¡æ ¼å·®ç‡']})")
                print()

    print("\nâœ… ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("=" * 60)
    print("ç«¶åˆè²·å–ä¾¡æ ¼ åˆ†æ")
    print("=" * 60)
    print()

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    janpara_data = load_all_data("janpara")
    iosys_data = load_all_data("iosys")

    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    generate_report(janpara_data, iosys_data)


if __name__ == "__main__":
    main()
