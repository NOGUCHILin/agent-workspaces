"""
ã‚²ã‚ªè²·å–ã‚µã‚¤ãƒˆã®æ§‹é€ èª¿æŸ»ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã‚²ã‚ªã®iPhoneè²·å–ãƒšãƒ¼ã‚¸ã®æ§‹é€ ã‚’èª¿æŸ»ã—ã€
ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æˆ¦ç•¥ã‚’æ±ºå®šã™ã‚‹ãŸã‚ã®æƒ…å ±ã‚’åé›†ã—ã¾ã™ã€‚
"""

from browser_scraper_base import BrowserScraperBase
from pathlib import Path
from datetime import datetime


class GeoInvestigator(BrowserScraperBase):
    """ã‚²ã‚ªã‚µã‚¤ãƒˆã®æ§‹é€ èª¿æŸ»ã‚¯ãƒ©ã‚¹"""

    BASE_URL = "https://buymobile.geo-online.co.jp/"

    def investigate(self) -> dict:
        """
        ã‚²ã‚ªã‚µã‚¤ãƒˆã®æ§‹é€ ã‚’èª¿æŸ»

        Returns:
            èª¿æŸ»çµæœã®è¾æ›¸
        """
        print("ğŸ” ã‚²ã‚ªã‚µã‚¤ãƒˆã®æ§‹é€ èª¿æŸ»ã‚’é–‹å§‹...")

        page = self.new_page()

        # ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
        print(f"ğŸ“„ {self.BASE_URL} ã«ã‚¢ã‚¯ã‚»ã‚¹ä¸­...")
        try:
            self.goto(page, self.BASE_URL, wait_until="networkidle")
            print("âœ… ã‚¢ã‚¯ã‚»ã‚¹æˆåŠŸï¼")
        except Exception as e:
            print(f"âŒ ã‚¢ã‚¯ã‚»ã‚¹å¤±æ•—: {e}")
            return {"error": str(e), "status": "failed"}

        # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆæ’®å½±
        screenshot_dir = Path(__file__).parent.parent / "data" / "screenshots"
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        screenshot_path = screenshot_dir / f"geo_main_{timestamp}.png"

        print(f"ğŸ“¸ ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆæ’®å½±: {screenshot_path}")
        self.take_screenshot(page, screenshot_path, full_page=True)

        # ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«å–å¾—
        title = page.title()
        print(f"ğŸ“ ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«: {title}")

        # ãƒšãƒ¼ã‚¸ã®HTMLã‚’éƒ¨åˆ†çš„ã«ä¿å­˜ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        html_content = page.content()
        html_path = screenshot_dir / f"geo_main_{timestamp}.html"
        html_path.write_text(html_content, encoding="utf-8")
        print(f"ğŸ’¾ HTMLä¿å­˜: {html_path}")

        # iPhoneãƒªãƒ³ã‚¯ã‚’æ¢ã™
        print("\nğŸ” iPhoneãƒªãƒ³ã‚¯ã‚’æ¤œç´¢ä¸­...")
        iphone_links = self._find_iphone_links(page)

        if not iphone_links:
            print("âš ï¸ iPhoneãƒªãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print("ğŸ’¡ æ‰‹å‹•ã§ãƒšãƒ¼ã‚¸ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        else:
            print(f"âœ… {len(iphone_links)}å€‹ã®iPhoneãƒªãƒ³ã‚¯ã‚’ç™ºè¦‹")
            for i, link in enumerate(iphone_links[:5], 1):
                print(f"  {i}. {link['text']}: {link['url']}")

        # ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³æ§‹é€ ã‚’èª¿æŸ»
        print("\nğŸ—‚ï¸ ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³æ§‹é€ ã‚’èª¿æŸ»ä¸­...")
        nav_structure = self._analyze_navigation(page)

        result = {
            "status": "success",
            "timestamp": timestamp,
            "url": self.BASE_URL,
            "title": title,
            "screenshot": str(screenshot_path),
            "html_file": str(html_path),
            "iphone_links": iphone_links,
            "navigation": nav_structure,
        }

        print("\nâœ… èª¿æŸ»å®Œäº†ï¼")
        return result

    def _find_iphone_links(self, page) -> list[dict]:
        """iPhoneã«é–¢é€£ã™ã‚‹ãƒªãƒ³ã‚¯ã‚’æ¤œç´¢"""
        links = []

        # ã‚ˆãã‚ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦ã™
        patterns = [
            'a:has-text("iPhone")',
            'a:has-text("ã‚¢ã‚¤ãƒ•ã‚©ãƒ³")',
            '[href*="iphone"]',
            '[href*="iPhone"]',
        ]

        for pattern in patterns:
            try:
                elements = page.query_selector_all(pattern)
                for el in elements:
                    text = el.inner_text().strip()
                    href = el.get_attribute("href")
                    if href and text:
                        # ç›¸å¯¾URLã‚’çµ¶å¯¾URLã«å¤‰æ›
                        if href.startswith("/"):
                            href = self.BASE_URL.rstrip("/") + href
                        links.append({"text": text, "url": href})
            except Exception:
                pass

        # é‡è¤‡å‰Šé™¤
        unique_links = []
        seen_urls = set()
        for link in links:
            if link["url"] not in seen_urls:
                unique_links.append(link)
                seen_urls.add(link["url"])

        return unique_links

    def _analyze_navigation(self, page) -> dict:
        """ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³æ§‹é€ ã‚’åˆ†æ"""
        nav = {}

        # ãƒ¡ã‚¤ãƒ³ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
        try:
            nav_elements = page.query_selector_all("nav a, .nav a, header a")
            nav["main_menu"] = [
                {
                    "text": el.inner_text().strip(),
                    "url": el.get_attribute("href"),
                }
                for el in nav_elements[:20]  # æœ€åˆã®20å€‹ã¾ã§
                if el.inner_text().strip()
            ]
        except Exception:
            nav["main_menu"] = []

        # ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ï¼ˆãƒ¢ãƒ‡ãƒ«é¸æŠãªã©ã«ä½¿ã‚ã‚Œã‚‹ã“ã¨ãŒã‚ã‚‹ï¼‰
        try:
            selects = page.query_selector_all("select")
            nav["select_boxes"] = []
            for select in selects:
                options = select.query_selector_all("option")
                nav["select_boxes"].append({
                    "id": select.get_attribute("id"),
                    "name": select.get_attribute("name"),
                    "options": [opt.inner_text().strip() for opt in options[:10]],
                })
        except Exception:
            nav["select_boxes"] = []

        return nav


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("=" * 60)
    print("ã‚²ã‚ªè²·å–ã‚µã‚¤ãƒˆæ§‹é€ èª¿æŸ»")
    print("=" * 60)
    print()

    # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œï¼ˆãƒ‡ãƒãƒƒã‚°æ™‚ã¯headless=Falseã«å¤‰æ›´ï¼‰
    with GeoInvestigator(headless=True, timeout=60000) as investigator:
        result = investigator.investigate()

    # çµæœã‚’ä¿å­˜
    if result.get("status") == "success":
        output_dir = Path(__file__).parent.parent / "data" / "investigations"
        output_dir.mkdir(parents=True, exist_ok=True)
        output_path = output_dir / f"geo_investigation_{result['timestamp']}.json"

        investigator.save_json(result, output_path)
        print(f"\nğŸ’¾ èª¿æŸ»çµæœã‚’ä¿å­˜: {output_path}")
        print("\nğŸ“‹ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("  1. ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’ç¢ºèª")
        print("  2. HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª")
        print("  3. iPhoneãƒªãƒ³ã‚¯ã‹ã‚‰è©³ç´°ãƒšãƒ¼ã‚¸ã«é·ç§»ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œæˆ")
    else:
        print(f"\nâŒ èª¿æŸ»å¤±æ•—: {result.get('error')}")


if __name__ == "__main__":
    main()
