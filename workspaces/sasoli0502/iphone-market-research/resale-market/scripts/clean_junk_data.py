"""
Dãƒ»ã‚¸ãƒ£ãƒ³ã‚¯ãƒ©ãƒ³ã‚¯ã®ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
S/A/B/Cãƒ©ãƒ³ã‚¯ã®ã¿æ®‹ã™
"""
import json
import re
from pathlib import Path
from typing import List, Dict


def is_junk_or_d_rank(product_name: str, description: str = "") -> bool:
    """
    å•†å“ãŒã‚¸ãƒ£ãƒ³ã‚¯ãƒ»Dãƒ©ãƒ³ã‚¯ã‹ã©ã†ã‹åˆ¤å®š

    Args:
        product_name: å•†å“å
        description: å•†å“èª¬æ˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

    Returns:
        True: ã‚¸ãƒ£ãƒ³ã‚¯ãƒ»Dãƒ©ãƒ³ã‚¯ï¼ˆé™¤å¤–å¯¾è±¡ï¼‰
        False: S/A/B/Cãƒ©ãƒ³ã‚¯ï¼ˆä¿æŒï¼‰
    """
    text = f"{product_name} {description}".upper()

    # ã‚¸ãƒ£ãƒ³ã‚¯åˆ¤å®šãƒ‘ã‚¿ãƒ¼ãƒ³
    junk_patterns = [
        r'ã‚¸ãƒ£ãƒ³ã‚¯',
        r'JUNK',
        r'Dãƒ©ãƒ³ã‚¯',
        r'D\s*ãƒ©ãƒ³ã‚¯',
        r'RANK\s*D',
        r'æ•…éšœ',
        r'å‹•ä½œä¸è‰¯',
        r'èµ·å‹•ä¸å¯',
        r'ãƒœã‚¿ãƒ³ä¸è‰¯',
        r'ã‚¿ãƒƒãƒä¸è‰¯',
        r'ç”»é¢å‰²ã‚Œ',
        r'æ¶²æ™¶å‰²ã‚Œ',
        r'ãƒãƒƒãƒ†ãƒªãƒ¼è†¨å¼µ',
        r'æ°´æ²¡',
        r'éƒ¨å“å–ã‚Š',
    ]

    for pattern in junk_patterns:
        if re.search(pattern, text, re.IGNORECASE):
            return True

    return False


def clean_json_file(input_path: Path, output_path: Path = None) -> Dict:
    """
    JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¸ãƒ£ãƒ³ã‚¯ãƒ»Dãƒ©ãƒ³ã‚¯ã‚’é™¤å¤–

    Args:
        input_path: å…¥åŠ›JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        output_path: å‡ºåŠ›JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆNoneã®å ´åˆã¯ä¸Šæ›¸ãï¼‰

    Returns:
        çµ±è¨ˆæƒ…å ±ï¼ˆå…ƒã®ä»¶æ•°ã€å‰Šé™¤ä»¶æ•°ã€æ®‹ã‚Šä»¶æ•°ï¼‰
    """
    if output_path is None:
        output_path = input_path

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    with open(input_path, 'r', encoding='utf-8') as f:
        products = json.load(f)

    original_count = len(products)

    # ã‚¸ãƒ£ãƒ³ã‚¯ãƒ»Dãƒ©ãƒ³ã‚¯é™¤å¤–
    cleaned_products = [
        p for p in products
        if not is_junk_or_d_rank(
            p.get('product_name', ''),
            p.get('description', '')
        )
    ]

    removed_count = original_count - len(cleaned_products)

    # ä¿å­˜
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(cleaned_products, f, ensure_ascii=False, indent=2)

    return {
        'file': input_path.name,
        'original': original_count,
        'removed': removed_count,
        'remaining': len(cleaned_products),
    }


def clean_all_rakuten_data():
    """æ¥½å¤©å¸‚å ´ã®å…¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚¸ãƒ£ãƒ³ã‚¯ãƒ»Dãƒ©ãƒ³ã‚¯ã‚’é™¤å¤–"""
    data_dir = Path('data/raw/rakuten')

    if not data_dir.exists():
        print(f"âŒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {data_dir}")
        return

    json_files = list(data_dir.glob('*.json'))

    if not json_files:
        print(f"âŒ JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {data_dir}")
        return

    print(f"ğŸ“ å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(json_files)}")
    print()

    total_original = 0
    total_removed = 0
    total_remaining = 0

    files_with_junk = []

    for json_file in sorted(json_files):
        stats = clean_json_file(json_file)

        total_original += stats['original']
        total_removed += stats['removed']
        total_remaining += stats['remaining']

        if stats['removed'] > 0:
            files_with_junk.append(stats)
            print(f"ğŸ—‘ï¸  {stats['file']}: {stats['removed']}ä»¶å‰Šé™¤ ({stats['original']} â†’ {stats['remaining']})")

    print()
    print("=" * 60)
    print(f"âœ… ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†")
    print(f"   ç·å•†å“æ•°: {total_original:,}ä»¶")
    print(f"   å‰Šé™¤ä»¶æ•°: {total_removed:,}ä»¶ ({total_removed/total_original*100:.1f}%)")
    print(f"   æ®‹ã‚Šä»¶æ•°: {total_remaining:,}ä»¶ ({total_remaining/total_original*100:.1f}%)")
    print(f"   ã‚¸ãƒ£ãƒ³ã‚¯å«æœ‰ãƒ•ã‚¡ã‚¤ãƒ«: {len(files_with_junk)}/{len(json_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
    print("=" * 60)


if __name__ == "__main__":
    clean_all_rakuten_data()
