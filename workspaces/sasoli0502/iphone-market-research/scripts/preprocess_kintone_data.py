"""
ãã‚“ã¨ã‚“CSVãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

æ©Ÿèƒ½:
- Shift-JISã§èª­ã¿è¾¼ã¿ã€UTF-8ã«å¤‰æ›
- é‡è¤‡åˆ—ã®å‡¦ç†ï¼ˆæ©Ÿç¨®ã€å®¹é‡ãŒ2åˆ—ã‚ã‚‹å•é¡Œï¼‰
- ã‚°ãƒ«ãƒ¼ãƒ—A/Bã®ãƒ•ãƒ©ã‚°ã‚’è¿½åŠ 
- é›†è¨ˆã‚­ãƒ¼ã‚’ä½œæˆ
- å‰å‡¦ç†æ¸ˆã¿CSVã‚’å‡ºåŠ›

ä½¿ç”¨æ–¹æ³•:
    uv run python scripts/preprocess_kintone_data.py kintone_YYYYMMDD.csv

å‡ºåŠ›:
    data/processed/preprocessed_YYYYMMDD.csv
"""

import pandas as pd
import sys
from pathlib import Path
from datetime import datetime


# =============================================================================
# ã‚°ãƒ«ãƒ¼ãƒ—A/Båˆ†é¡å®šç¾©
# =============================================================================

# ä¸å…·åˆ - ã‚°ãƒ«ãƒ¼ãƒ—A: ãŠå®¢æ§˜ãŒèªè­˜ã—ã‚„ã™ã„ï¼ˆæ¸›é¡ç‡ã‚’ä¸Šã’ã«ãã„ï¼‰
DEFECT_GROUP_A = [
    "ä¸å…·åˆãªã©[TouchIDã‚„FaceIDã®æ•…éšœ]",
    "ä¸å…·åˆãªã©[ã‚µã‚¤ãƒ‰ãƒœã‚¿ãƒ³ã®æ•…éšœ]",
    "ä¸å…·åˆãªã©[æ­£å¸¸ã«èµ·å‹•ã—ãªã„]",
    "ä¸å…·åˆãªã©[åˆæœŸåŒ–ã§ããªã„]",
    "ä¸å…·åˆãªã©[ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ©ç”¨åˆ¶é™]",
]

# ä¸å…·åˆ - ã‚°ãƒ«ãƒ¼ãƒ—B: ãŠå®¢æ§˜ãŒèªè­˜ã—ã«ãã„ï¼ˆæ¸›é¡ä½™åœ°ã‚ã‚Šï¼‰
DEFECT_GROUP_B = [
    "ä¸å…·åˆãªã©[ãƒãƒƒãƒ†ãƒªãƒ¼ã®åŠ£åŒ–]",  # æœ€é‡è¦
    "ä¸å…·åˆãªã©[è¡¨ç¤ºã‚„ã‚¿ãƒƒãƒæ“ä½œã®åŠ£åŒ–]",
    "ä¸å…·åˆãªã©[ã‚¢ã‚¦ãƒˆã‚«ãƒ¡ãƒ©ã®æ•…éšœ]",
    "ä¸å…·åˆãªã©[ãƒã‚¤ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¸å…·åˆ]",
    "ä¸å…·åˆãªã©[ç«¯æœ«ä¸Šéƒ¨ã®ä¸å…·åˆ]",
    "ä¸å…·åˆãªã©[ç«¯æœ«ä¸‹éƒ¨ã®ä¸å…·åˆ]",
    "ä¸å…·åˆãªã©[Wi-Fiã‚„Bluetoothã®ä¸å…·åˆ]",
    "ä¸å…·åˆãªã©[ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã®æ•…éšœ]",
    "ä¸å…·åˆãªã©[æ°´æ²¡æ­´ã‚ã‚Š]",
    "ä¸å…·åˆãªã©[ãã®ä»–]",
]

# ä¿®ç† - ã‚°ãƒ«ãƒ¼ãƒ—A: ãŠå®¢æ§˜ãŒèªè­˜ã—ã‚„ã™ã„ï¼ˆæ¸›é¡ç‡ã‚’ä¸Šã’ã«ãã„ï¼‰
REPAIR_GROUP_A = [
    "ä¿®ç†[ç”»é¢ä¿®ç†]",
    "ä¿®ç†[ã‚¢ã‚¦ãƒˆã‚«ãƒ¡ãƒ©ã‚¬ãƒ©ã‚¹äº¤æ›]",
]

# ä¿®ç† - ã‚°ãƒ«ãƒ¼ãƒ—B: ãŠå®¢æ§˜ãŒèªè­˜ã—ã«ãã„ï¼ˆæ¸›é¡ä½™åœ°ã‚ã‚Šï¼‰
REPAIR_GROUP_B = [
    "ä¿®ç†[ãƒ‰ãƒƒã‚¯ä¿®ç†]",
    "ä¿®ç†[ã‚¤ãƒ³ã‚«ãƒ¡ãƒ©ä¿®ç†]",
    "ä¿®ç†[ã‚¢ã‚¦ãƒˆã‚«ãƒ¡ãƒ©ä¿®ç†]",
    "ä¿®ç†[ã‚¿ãƒ—ãƒ†ã‚£ãƒƒã‚¯ã‚¨ãƒ³ã‚¸ãƒ³ä¿®ç†]",
    "ä¿®ç†[ãƒãƒƒãƒ†ãƒªãƒ¼äº¤æ›]",
]

# =============================================================================
# é€²æ—ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®åˆ†é¡ï¼ˆ3æ®µéšãƒ•ã‚¡ãƒãƒ«ï¼‰
# =============================================================================
# ãƒ•ãƒ­ãƒ¼:
#   ä»®æŸ»å®š â”€â”¬â†’ æ¢±åŒ…ã‚­ãƒƒãƒˆç™ºé€ â†’ æˆç´„
#           â””â†’ é›†è· â†’ æˆç´„

# æ®µéš2A: æ¢±åŒ…ã‚­ãƒƒãƒˆãƒ«ãƒ¼ãƒˆï¼ˆãŠå®¢æ§˜ãŒè‡ªåˆ†ã§æ¢±åŒ…ã—ã¦é€ã‚‹ï¼‰
KIT_ROUTE_STATUSES = [
    "æ¢±åŒ…ã‚­ãƒƒãƒˆç™ºé€å®Œäº†",
    "æ¢±åŒ…ã‚­ãƒƒãƒˆç™ºé€è¦æœ›ã‚ã‚Š",
]

# æ®µéš2B: é›†è·ãƒ«ãƒ¼ãƒˆï¼ˆãƒ¤ãƒãƒˆãŒé›†è·ã«è¡Œãï¼‰
PICKUP_ROUTE_STATUSES = [
    "é›†è·äºˆå®šæ—¥ç¢ºå®š",
    "é›†è·ä¾é ¼å—ä»˜æ¸ˆã¿",
]

# æ®µéš3ã®é€”ä¸­: æœ¬æŸ»å®šä¸­ï¼ˆæ¢±åŒ…ã‚­ãƒƒãƒˆ or é›†è·ã‹ã‚‰é€²ã‚“ã ï¼‰
ASSESSMENT_STATUSES = [
    "æœ¬æŸ»å®šé–‹å§‹",
    "æœ¬æŸ»å®šå®Œäº†",
]

# æ®µéš3: æˆç´„
CONTRACT_STATUSES = [
    "æ¥åº—è²·å–æˆç´„",
    "å®…é…è²·å–æˆç´„",
    "è²©å£²å®Œäº†",
    "å‡ºå“å®Œäº†",
]

# ä¸æˆç´„ï¼ˆé›¢è„±ï¼‰
LOST_STATUSES = [
    "æœ¬æŸ»å®šå‰ä¸æˆç´„",
    "å®…é…è²·å–ä¸æˆç´„",
    "æ¥åº—è²·å–ä¸æˆç´„",
]

# æ¥åº—ãƒ•ãƒ­ãƒ¼ï¼ˆå®…é…ã¨ã¯åˆ¥ï¼‰
VISIT_STATUSES = [
    "æ¥åº—è²·å–æˆç´„",
    "æ¥åº—è²·å–ä¸æˆç´„",
]


def load_kintone_csv(filepath: str) -> pd.DataFrame:
    """ãã‚“ã¨ã‚“CSVã‚’Shift-JISã§èª­ã¿è¾¼ã‚€"""
    df = pd.read_csv(filepath, encoding="shift-jis", dtype=str)
    return df


def fix_duplicate_columns(df: pd.DataFrame) -> pd.DataFrame:
    """é‡è¤‡åˆ—ã‚’å‡¦ç†ï¼ˆæ©Ÿç¨®ã¨å®¹é‡ãŒ2åˆ—ã‚ã‚‹å•é¡Œï¼‰"""
    # åˆ—åã‚’å–å¾—
    cols = df.columns.tolist()

    # é‡è¤‡åˆ—ã®å‡¦ç†
    # æ©Ÿç¨®: 1åˆ—ç›®ã¯ç©ºã€2åˆ—ç›®ã«å€¤ãŒã‚ã‚‹
    # å®¹é‡: 1åˆ—ç›®ã¯ç©ºã€2åˆ—ç›®ã«å€¤ãŒã‚ã‚‹

    # æ–°ã—ã„åˆ—åã‚’ä½œæˆï¼ˆé‡è¤‡ã‚’è§£æ¶ˆï¼‰
    new_cols = []
    seen = {}
    for col in cols:
        if col in seen:
            seen[col] += 1
            new_cols.append(f"{col}_{seen[col]}")
        else:
            seen[col] = 0
            new_cols.append(col)

    df.columns = new_cols

    # æ©Ÿç¨®: ç©ºã§ãªã„æ–¹ã‚’æ¡ç”¨
    if "æ©Ÿç¨®" in df.columns and "æ©Ÿç¨®_1" in df.columns:
        df["æ©Ÿç¨®"] = df.apply(
            lambda row: row["æ©Ÿç¨®_1"] if pd.isna(row["æ©Ÿç¨®"]) or row["æ©Ÿç¨®"] == "" else row["æ©Ÿç¨®"],
            axis=1
        )
        df = df.drop(columns=["æ©Ÿç¨®_1"])

    # å®¹é‡: ç©ºã§ãªã„æ–¹ã‚’æ¡ç”¨
    if "å®¹é‡" in df.columns and "å®¹é‡_1" in df.columns:
        df["å®¹é‡"] = df.apply(
            lambda row: row["å®¹é‡_1"] if pd.isna(row["å®¹é‡"]) or row["å®¹é‡"] == "" else row["å®¹é‡"],
            axis=1
        )
        df = df.drop(columns=["å®¹é‡_1"])

    return df


def has_defect_or_repair(row: pd.Series, columns: list[str]) -> bool:
    """æŒ‡å®šã—ãŸåˆ—ã®ã„ãšã‚Œã‹ã«"1"ãŒã‚ã‚‹ã‹åˆ¤å®š"""
    for col in columns:
        if col in row.index:
            val = row[col]
            if pd.notna(val) and str(val).strip() == "1":
                return True
    return False


def add_group_flags(df: pd.DataFrame) -> pd.DataFrame:
    """ã‚°ãƒ«ãƒ¼ãƒ—A/Bã®ãƒ•ãƒ©ã‚°ã‚’è¿½åŠ """
    # ä¸å…·åˆã‚°ãƒ«ãƒ¼ãƒ—A
    df["ä¸å…·åˆ_ã‚°ãƒ«ãƒ¼ãƒ—A"] = df.apply(
        lambda row: has_defect_or_repair(row, DEFECT_GROUP_A), axis=1
    )

    # ä¸å…·åˆã‚°ãƒ«ãƒ¼ãƒ—B
    df["ä¸å…·åˆ_ã‚°ãƒ«ãƒ¼ãƒ—B"] = df.apply(
        lambda row: has_defect_or_repair(row, DEFECT_GROUP_B), axis=1
    )

    # ä¿®ç†ã‚°ãƒ«ãƒ¼ãƒ—A
    df["ä¿®ç†_ã‚°ãƒ«ãƒ¼ãƒ—A"] = df.apply(
        lambda row: has_defect_or_repair(row, REPAIR_GROUP_A), axis=1
    )

    # ä¿®ç†ã‚°ãƒ«ãƒ¼ãƒ—B
    df["ä¿®ç†_ã‚°ãƒ«ãƒ¼ãƒ—B"] = df.apply(
        lambda row: has_defect_or_repair(row, REPAIR_GROUP_B), axis=1
    )

    # ãƒãƒƒãƒ†ãƒªãƒ¼åŠ£åŒ–ã®ã¿ã®ãƒ•ãƒ©ã‚°ï¼ˆæœ€é‡è¦é …ç›®ï¼‰
    df["ãƒãƒƒãƒ†ãƒªãƒ¼åŠ£åŒ–ã‚ã‚Š"] = df.apply(
        lambda row: has_defect_or_repair(row, ["ä¸å…·åˆãªã©[ãƒãƒƒãƒ†ãƒªãƒ¼ã®åŠ£åŒ–]"]), axis=1
    )

    # ä¸å…·åˆãªã—ãƒ•ãƒ©ã‚°
    all_defects = DEFECT_GROUP_A + DEFECT_GROUP_B
    df["ä¸å…·åˆãªã—"] = df.apply(
        lambda row: not has_defect_or_repair(row, all_defects), axis=1
    )

    # ä¿®ç†ãªã—ãƒ•ãƒ©ã‚°
    all_repairs = REPAIR_GROUP_A + REPAIR_GROUP_B
    df["ä¿®ç†ãªã—"] = df.apply(
        lambda row: not has_defect_or_repair(row, all_repairs), axis=1
    )

    return df


def add_funnel_flags(df: pd.DataFrame) -> pd.DataFrame:
    """3æ®µéšãƒ•ã‚¡ãƒãƒ«ã®ãƒ•ãƒ©ã‚°ã‚’è¿½åŠ """
    # æ®µéš2ä»¥é™ã«é€²ã‚“ã ã‚‚ã®ï¼ˆæ¢±åŒ…ã‚­ãƒƒãƒˆ or é›†è· or æœ¬æŸ»å®š or æˆç´„ or å®…é…ä¸æˆç´„ï¼‰
    stage2_or_later = (
        KIT_ROUTE_STATUSES +
        PICKUP_ROUTE_STATUSES +
        ASSESSMENT_STATUSES +
        CONTRACT_STATUSES +
        ["å®…é…è²·å–ä¸æˆç´„"]
    )
    df["æ®µéš2ä»¥é™"] = df["é€²æ—"].isin(stage2_or_later)

    # æ®µéš2A: æ¢±åŒ…ã‚­ãƒƒãƒˆãƒ«ãƒ¼ãƒˆï¼ˆæ¢±åŒ…ã‚­ãƒƒãƒˆç™ºé€ or ãã®å¾Œã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼‰
    # æ¢±åŒ…ã‚­ãƒƒãƒˆã‹ã‚‰é€²ã‚“ã äººã¯æœ¬æŸ»å®šãƒ»æˆç´„ã«ã‚‚é€²ã‚€
    df["æ¢±åŒ…ã‚­ãƒƒãƒˆãƒ«ãƒ¼ãƒˆ"] = df["é€²æ—"].isin(KIT_ROUTE_STATUSES)

    # æ®µéš2B: é›†è·ãƒ«ãƒ¼ãƒˆï¼ˆé›†è· or ãã®å¾Œã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼‰
    # é›†è·ã‹ã‚‰é€²ã‚“ã äººã¯æœ¬æŸ»å®šãƒ»æˆç´„ã«ã‚‚é€²ã‚€
    df["é›†è·ãƒ«ãƒ¼ãƒˆ"] = df["é€²æ—"].isin(PICKUP_ROUTE_STATUSES)

    # æ®µéš2ï¼ˆæ¢±åŒ…ã‚­ãƒƒãƒˆ or é›†è·ï¼‰ã«é€²ã‚“ã 
    df["æ¢±åŒ…ã‚­ãƒƒãƒˆoré›†è·"] = df["æ¢±åŒ…ã‚­ãƒƒãƒˆãƒ«ãƒ¼ãƒˆ"] | df["é›†è·ãƒ«ãƒ¼ãƒˆ"]

    # æœ¬æŸ»å®šä¸­
    df["æœ¬æŸ»å®šä¸­"] = df["é€²æ—"].isin(ASSESSMENT_STATUSES)

    # æˆç´„ï¼ˆæ®µéš3ï¼‰
    df["æˆç´„"] = df["é€²æ—"].isin(CONTRACT_STATUSES)

    # ä¸æˆç´„ï¼ˆé›¢è„±ï¼‰
    df["ä¸æˆç´„"] = df["é€²æ—"].isin(LOST_STATUSES)

    # æ¥åº—ãƒ•ãƒ­ãƒ¼ï¼ˆå®…é…ã¨ã¯åˆ¥ï¼‰
    df["æ¥åº—"] = df["é€²æ—"].isin(VISIT_STATUSES)

    return df


def add_aggregation_key(df: pd.DataFrame) -> pd.DataFrame:
    """é›†è¨ˆã‚­ãƒ¼ã‚’ä½œæˆ"""
    # åŸºæœ¬ã‚­ãƒ¼: æ©Ÿç¨®_å®¹é‡_ãƒ©ãƒ³ã‚¯
    df["é›†è¨ˆã‚­ãƒ¼_åŸºæœ¬"] = df["æ©Ÿç¨®"] + "_" + df["å®¹é‡"] + "_" + df["ãƒ©ãƒ³ã‚¯"]

    # è©³ç´°ã‚­ãƒ¼: åŸºæœ¬ã‚­ãƒ¼ + ã‚°ãƒ«ãƒ¼ãƒ—ãƒ•ãƒ©ã‚°
    df["é›†è¨ˆã‚­ãƒ¼_è©³ç´°"] = (
        df["é›†è¨ˆã‚­ãƒ¼_åŸºæœ¬"] + "_" +
        "ä¸A:" + df["ä¸å…·åˆ_ã‚°ãƒ«ãƒ¼ãƒ—A"].astype(str) + "_" +
        "ä¸B:" + df["ä¸å…·åˆ_ã‚°ãƒ«ãƒ¼ãƒ—B"].astype(str) + "_" +
        "ä¿®A:" + df["ä¿®ç†_ã‚°ãƒ«ãƒ¼ãƒ—A"].astype(str) + "_" +
        "ä¿®B:" + df["ä¿®ç†_ã‚°ãƒ«ãƒ¼ãƒ—B"].astype(str)
    )

    return df


def convert_price_columns(df: pd.DataFrame) -> pd.DataFrame:
    """ä¾¡æ ¼åˆ—ã‚’æ•°å€¤å‹ã«å¤‰æ›"""
    price_cols = ["æœ€é«˜æç¤ºä¾¡æ ¼", "æœ€ä½æç¤ºä¾¡æ ¼", "æœ€çµ‚è²·å–ä¾¡æ ¼", "æƒ³å®šè²©å£²ä¾¡æ ¼", "ç²—åˆ©(æ‰‹æ•°æ–™å¼•)", "å¸å£²ä¾¡æ ¼"]

    for col in price_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")

    return df


def convert_date_columns(df: pd.DataFrame) -> pd.DataFrame:
    """æ—¥ä»˜åˆ—ã‚’datetimeå‹ã«å¤‰æ›"""
    date_cols = ["ä½œæˆæ—¥æ™‚", "è²·å–æ—¥"]

    for col in date_cols:
        if col in df.columns:
            df[col] = pd.to_datetime(df[col], errors="coerce")

    return df


def preprocess(input_path: str, output_path: str) -> pd.DataFrame:
    """ãƒ¡ã‚¤ãƒ³å‰å‡¦ç†é–¢æ•°"""
    print(f"ğŸ“‚ èª­ã¿è¾¼ã¿: {input_path}")

    # 1. CSVã‚’èª­ã¿è¾¼ã¿
    df = load_kintone_csv(input_path)
    print(f"   - èª­ã¿è¾¼ã¿ä»¶æ•°: {len(df):,}ä»¶")

    # 2. é‡è¤‡åˆ—ã‚’å‡¦ç†
    df = fix_duplicate_columns(df)
    print("   - é‡è¤‡åˆ—ã‚’å‡¦ç†")

    # 3. ã‚°ãƒ«ãƒ¼ãƒ—A/Bãƒ•ãƒ©ã‚°ã‚’è¿½åŠ 
    df = add_group_flags(df)
    print("   - ã‚°ãƒ«ãƒ¼ãƒ—A/Bãƒ•ãƒ©ã‚°ã‚’è¿½åŠ ")

    # 4. ãƒ•ã‚¡ãƒãƒ«ãƒ•ãƒ©ã‚°ã‚’è¿½åŠ ï¼ˆæ¢±åŒ…ã‚­ãƒƒãƒˆãƒ»é›†è·ãƒ»æˆç´„ï¼‰
    df = add_funnel_flags(df)
    print("   - ãƒ•ã‚¡ãƒãƒ«ãƒ•ãƒ©ã‚°ã‚’è¿½åŠ ")

    # 5. é›†è¨ˆã‚­ãƒ¼ã‚’ä½œæˆ
    df = add_aggregation_key(df)
    print("   - é›†è¨ˆã‚­ãƒ¼ã‚’ä½œæˆ")

    # 6. ä¾¡æ ¼åˆ—ã‚’æ•°å€¤å‹ã«å¤‰æ›
    df = convert_price_columns(df)
    print("   - ä¾¡æ ¼åˆ—ã‚’æ•°å€¤å‹ã«å¤‰æ›")

    # 7. æ—¥ä»˜åˆ—ã‚’å¤‰æ›
    df = convert_date_columns(df)
    print("   - æ—¥ä»˜åˆ—ã‚’å¤‰æ›")

    # 8. å‡ºåŠ›
    df.to_csv(output_path, index=False, encoding="utf-8-sig")
    print(f"âœ… å‡ºåŠ›: {output_path}")
    print(f"   - å‡ºåŠ›ä»¶æ•°: {len(df):,}ä»¶")

    # çµ±è¨ˆã‚µãƒãƒªãƒ¼
    total = len(df)
    kit_route = df['æ¢±åŒ…ã‚­ãƒƒãƒˆãƒ«ãƒ¼ãƒˆ'].sum()
    pickup_route = df['é›†è·ãƒ«ãƒ¼ãƒˆ'].sum()
    assessment = df['æœ¬æŸ»å®šä¸­'].sum()
    contracted = df['æˆç´„'].sum()
    lost = df['ä¸æˆç´„'].sum()
    visit = df['æ¥åº—'].sum()

    # æ®µéš2ä»¥é™ã«é€²ã‚“ã ç·æ•°ï¼ˆæˆç´„ + æ¢±åŒ…ã‚­ãƒƒãƒˆoré›†è· + æœ¬æŸ»å®šä¸­ + ä¸æˆç´„ï¼‰
    stage2_total = contracted + kit_route + pickup_route + assessment + lost

    print("\nğŸ“Š çµ±è¨ˆã‚µãƒãƒªãƒ¼:")
    print(f"   - ä»®æŸ»å®šæ•°: {total:,}ä»¶")
    print("")
    print("   ã€3æ®µéšãƒ•ã‚¡ãƒãƒ«ã€‘")
    print(f"   æ®µéš1: ä»®æŸ»å®š {total:,}ä»¶")
    print(f"   æ®µéš2ä»¥é™: {stage2_total:,}ä»¶ (CVR: {stage2_total/total*100:.1f}%)")
    print(f"      - æ¢±åŒ…ã‚­ãƒƒãƒˆãƒ«ãƒ¼ãƒˆ: {kit_route:,}ä»¶")
    print(f"      - é›†è·ãƒ«ãƒ¼ãƒˆ: {pickup_route:,}ä»¶")
    print(f"      - æœ¬æŸ»å®šä¸­: {assessment:,}ä»¶")
    print(f"      - æˆç´„: {contracted:,}ä»¶")
    print(f"      - ä¸æˆç´„: {lost:,}ä»¶")
    print("")
    print(f"   æ®µéš3: æˆç´„ {contracted:,}ä»¶")
    print(f"      - æˆç´„ç‡ï¼ˆæ®µéš2ä»¥é™ã‹ã‚‰ï¼‰: {contracted/stage2_total*100:.1f}%")
    print(f"      - æˆç´„ç‡ï¼ˆå…¨ä½“ã‹ã‚‰ï¼‰: {contracted/total*100:.1f}%")
    print(f"      - ä¸æˆç´„ç‡ï¼ˆæ®µéš2ä»¥é™ã‹ã‚‰ï¼‰: {lost/stage2_total*100:.1f}%")
    print("")
    print(f"   ã€æ¥åº—ã€‘{visit:,}ä»¶ï¼ˆåˆ¥ãƒ•ãƒ­ãƒ¼ï¼‰")
    print("")
    print("   ã€ä¸å…·åˆãƒ»ä¿®ç†ã€‘")
    print(f"   - ä¸å…·åˆã‚°ãƒ«ãƒ¼ãƒ—Aã‚ã‚Š: {df['ä¸å…·åˆ_ã‚°ãƒ«ãƒ¼ãƒ—A'].sum():,}ä»¶")
    print(f"   - ä¸å…·åˆã‚°ãƒ«ãƒ¼ãƒ—Bã‚ã‚Š: {df['ä¸å…·åˆ_ã‚°ãƒ«ãƒ¼ãƒ—B'].sum():,}ä»¶")
    print(f"   - ãƒãƒƒãƒ†ãƒªãƒ¼åŠ£åŒ–ã‚ã‚Š: {df['ãƒãƒƒãƒ†ãƒªãƒ¼åŠ£åŒ–ã‚ã‚Š'].sum():,}ä»¶")
    print(f"   - ä¿®ç†ã‚°ãƒ«ãƒ¼ãƒ—Aã‚ã‚Š: {df['ä¿®ç†_ã‚°ãƒ«ãƒ¼ãƒ—A'].sum():,}ä»¶")
    print(f"   - ä¿®ç†ã‚°ãƒ«ãƒ¼ãƒ—Bã‚ã‚Š: {df['ä¿®ç†_ã‚°ãƒ«ãƒ¼ãƒ—B'].sum():,}ä»¶")
    print(f"   - ä¸å…·åˆãƒ»ä¿®ç†ãªã—: {(df['ä¸å…·åˆãªã—'] & df['ä¿®ç†ãªã—']).sum():,}ä»¶")

    return df


def main():
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: uv run python scripts/preprocess_kintone_data.py <å…¥åŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«>")
        print("ä¾‹: uv run python scripts/preprocess_kintone_data.py kintone_20251125.csv")
        sys.exit(1)

    input_file = sys.argv[1]
    input_path = Path(input_file)

    if not input_path.exists():
        # ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§æ¢ã™
        input_path = Path(__file__).parent.parent / input_file
        if not input_path.exists():
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_file}")
            sys.exit(1)

    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
    today = datetime.now().strftime("%Y%m%d")
    output_dir = Path(__file__).parent.parent / "data" / "processed"
    output_dir.mkdir(parents=True, exist_ok=True)
    output_path = output_dir / f"preprocessed_{today}.csv"

    preprocess(str(input_path), str(output_path))


if __name__ == "__main__":
    main()
